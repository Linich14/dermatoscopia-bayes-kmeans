"""
Sistema de partici√≥n de datos para entrenamiento y evaluaci√≥n de modelos.

Este m√≥dulo proporciona funcionalidades para dividir el conjunto de datos de im√°genes
dermatosc√≥picas en conjuntos de entrenamiento, validaci√≥n y prueba. La partici√≥n se
realiza a nivel de imagen (no de p√≠xel) para evitar el data leakage y garantizar
una evaluaci√≥n robusta de los modelos de segmentaci√≥n.

Caracter√≠sticas principales:
- Partici√≥n estratificada a nivel de imagen
- Reproducibilidad mediante semilla fija
- Distribuci√≥n est√°ndar: 60% entrenamiento, 20% validaci√≥n, 20% prueba
- Preservaci√≥n de estructura de datos original


"""

import numpy as np
from sklearn.model_selection import train_test_split
from config.configuracion import SEED

def particionar_datos(imagenes):
    """
    Realiza la partici√≥n estratificada de datos por imagen en conjuntos de entrenamiento, validaci√≥n y test.
    
    Esta funci√≥n divide el conjunto completo de im√°genes en tres subconjuntos disjuntos
    siguiendo la distribuci√≥n est√°ndar para machine learning m√©dico. La partici√≥n se
    realiza a nivel de imagen completa para evitar data leakage, donde p√≠xeles de la
    misma imagen podr√≠an aparecer tanto en entrenamiento como en evaluaci√≥n.
    
    Distribuci√≥n de datos:
    - Entrenamiento: 60% de las im√°genes (para entrenar modelos)
    - Validaci√≥n: 20% de las im√°genes (para ajuste de hiperpar√°metros)
    - Prueba: 20% de las im√°genes (para evaluaci√≥n final)
    
    Args:
        imagenes (list): Lista de diccionarios con estructura:
            [
                {
                    'nombre': str,           # Nombre base del archivo
                    'imagen': np.ndarray,    # Imagen RGB (H,W,3) normalizada
                    'mascara': np.ndarray    # M√°scara binaria (H,W)
                },
                ...
            ]
    
    Returns:
        tuple: Tupla de tres listas (train, val, test) cada una conteniendo
               diccionarios con la misma estructura que la entrada:
               - train (list): Conjunto de entrenamiento (60%)
               - val (list): Conjunto de validaci√≥n (20%)  
               - test (list): Conjunto de prueba (20%)
    
    Note:
        - Utiliza semilla fija (SEED) para garantizar reproducibilidad
        - La partici√≥n es aleatoria pero estratificada
        - Se preserva la estructura original de cada elemento
        - Si hay menos de 5 im√°genes, se ajusta la distribuci√≥n autom√°ticamente
        
    Example:
        >>> imagenes = cargar_imagenes_y_mascaras()
        >>> train, val, test = particionar_datos(imagenes)
        >>> print(f"Entrenamiento: {len(train)} im√°genes")
        >>> print(f"Validaci√≥n: {len(val)} im√°genes") 
        >>> print(f"Prueba: {len(test)} im√°genes")
        
    Raises:
        ValueError: Si la lista de im√°genes est√° vac√≠a
        RuntimeError: Si hay problemas en la partici√≥n de datos
    """
    # Validar entrada
    if not imagenes:
        print("‚ö†Ô∏è  Lista de im√°genes vac√≠a, devolviendo conjuntos vac√≠os")
        return [], [], []
    
    if len(imagenes) < 3:
        print(f"‚ö†Ô∏è  Muy pocas im√°genes ({len(imagenes)}) para partici√≥n est√°ndar")
        print("üìù Usando todas las im√°genes para entrenamiento")
        return imagenes, [], []
    
    print(f"üìä Particionando {len(imagenes)} im√°genes en conjuntos de datos...")
    
    try:
        # Crear array de √≠ndices para la partici√≥n
        indices = np.arange(len(imagenes))
        
        # Primera partici√≥n: separar entrenamiento (60%) del resto (40%)
        train_idx, temp_idx = train_test_split(
            indices, 
            test_size=0.4,           # 40% para validaci√≥n + prueba
            random_state=SEED,       # Reproducibilidad
            shuffle=True             # Mezclar antes de dividir
        )
        
        # Segunda partici√≥n: dividir el 40% restante en validaci√≥n (20%) y prueba (20%)
        val_idx, test_idx = train_test_split(
            temp_idx,
            test_size=0.5,           # 50% del 40% = 20% total
            random_state=SEED,       # Misma semilla para reproducibilidad
            shuffle=True
        )
        
        # Crear conjuntos de datos usando los √≠ndices seleccionados
        train = [imagenes[i] for i in train_idx]
        val = [imagenes[i] for i in val_idx]
        test = [imagenes[i] for i in test_idx]
        
        # Verificar integridad de la partici√≥n
        total_particionado = len(train) + len(val) + len(test)
        if total_particionado != len(imagenes):
            raise RuntimeError(f"Error en partici√≥n: {total_particionado} != {len(imagenes)}")
        
        # Reporte de resultados
        print(f"‚úÖ Partici√≥n completada exitosamente:")
        print(f"   üìö Entrenamiento: {len(train)} im√°genes ({len(train)/len(imagenes)*100:.1f}%)")
        print(f"   üîç Validaci√≥n: {len(val)} im√°genes ({len(val)/len(imagenes)*100:.1f}%)")
        print(f"   üß™ Prueba: {len(test)} im√°genes ({len(test)/len(imagenes)*100:.1f}%)")
        
        # Verificar que no hay solapamiento entre conjuntos
        nombres_train = {img['nombre'] for img in train}
        nombres_val = {img['nombre'] for img in val}
        nombres_test = {img['nombre'] for img in test}
        
        if nombres_train & nombres_val or nombres_train & nombres_test or nombres_val & nombres_test:
            raise RuntimeError("‚ùå Detectado solapamiento entre conjuntos de datos")
        
        print("‚úÖ Verificaci√≥n de integridad: Sin solapamiento entre conjuntos")
        
        return train, val, test
        
    except Exception as e:
        print(f"‚ùå Error durante la partici√≥n de datos: {str(e)}")
        raise RuntimeError(f"Fallo en la partici√≥n de datos: {str(e)}")

def obtener_estadisticas_particion(train, val, test):
    """
    Calcula estad√≠sticas descriptivas de la partici√≥n de datos.
    
    Esta funci√≥n proporciona un an√°lisis detallado de c√≥mo se distribuyeron
    los datos entre los conjuntos de entrenamiento, validaci√≥n y prueba,
    incluyendo estad√≠sticas sobre p√≠xeles de lesi√≥n y balance de clases.
    
    Args:
        train (list): Conjunto de entrenamiento
        val (list): Conjunto de validaci√≥n  
        test (list): Conjunto de prueba
        
    Returns:
        dict: Diccionario con estad√≠sticas de la partici√≥n:
            {
                'total_imagenes': int,
                'train': {'imagenes': int, 'pixeles_lesion': int, 'pixeles_total': int},
                'val': {'imagenes': int, 'pixeles_lesion': int, 'pixeles_total': int},
                'test': {'imagenes': int, 'pixeles_lesion': int, 'pixeles_total': int},
                'balance_clases': {'train': float, 'val': float, 'test': float}
            }
    """
    def analizar_conjunto(conjunto, nombre):
        """Analiza un conjunto de datos espec√≠fico"""
        if not conjunto:
            return {'imagenes': 0, 'pixeles_lesion': 0, 'pixeles_total': 0, 'balance': 0.0}
        
        total_imagenes = len(conjunto)
        total_pixeles_lesion = sum(np.sum(img['mascara']) for img in conjunto)
        total_pixeles = sum(img['mascara'].size for img in conjunto)
        balance = total_pixeles_lesion / total_pixeles if total_pixeles > 0 else 0.0
        
        print(f"üìä Estad√≠sticas {nombre}:")
        print(f"   Im√°genes: {total_imagenes}")
        print(f"   P√≠xeles de lesi√≥n: {total_pixeles_lesion:,}")
        print(f"   P√≠xeles totales: {total_pixeles:,}")
        print(f"   Balance de clases: {balance:.3f} ({balance*100:.1f}% lesi√≥n)")
        
        return {
            'imagenes': total_imagenes,
            'pixeles_lesion': total_pixeles_lesion,
            'pixeles_total': total_pixeles,
            'balance': balance
        }
    
    print("\nüìà An√°lisis estad√≠stico de la partici√≥n:")
    
    # Analizar cada conjunto
    stats_train = analizar_conjunto(train, "Entrenamiento")
    stats_val = analizar_conjunto(val, "Validaci√≥n")
    stats_test = analizar_conjunto(test, "Prueba")
    
    # Estad√≠sticas globales
    total_imagenes = stats_train['imagenes'] + stats_val['imagenes'] + stats_test['imagenes']
    
    estadisticas = {
        'total_imagenes': total_imagenes,
        'train': stats_train,
        'val': stats_val,
        'test': stats_test,
        'balance_clases': {
            'train': stats_train['balance'],
            'val': stats_val['balance'],
            'test': stats_test['balance']
        }
    }
    
    return estadisticas
